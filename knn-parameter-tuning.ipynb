{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN with Parameter Tuning\n",
    "\n",
    "In this project, I implement from scratch the k-NN algorithm on a dataset containing breast cancer data. \n",
    "I also implement my own cross-validation algorithm in order to tune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math \n",
    "import statistics\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(p, q):\n",
    "    sum_cathetus = 0\n",
    "    for i in range(0, len(p)):\n",
    "        cathetus = (p[i] - q[i])**2\n",
    "        sum_cathetus += cathetus\n",
    "    \n",
    "    return math.sqrt(sum_cathetus)\n",
    "\n",
    "    \n",
    "def knn(x_train, y_train, x_test, k, distance_func):\n",
    "\n",
    "    x_train_normalized = ((x_train - x_train.min()) / (x_train.max() - x_train.min()) )\n",
    "    x_test_normalized = ((x_test - x_train.min()) / (x_train.max() - x_train.min()) )\n",
    "\n",
    "    predictions = []\n",
    "    for row, query_point in x_test_normalized.iterrows():\n",
    "        distances = []\n",
    "        labels = []\n",
    "\n",
    "        #Get distances between each x_train point and the query point\n",
    "        for index in range(0, len(x_train_normalized)):\n",
    "            d = distance_func(x_train_normalized.iloc[index], query_point)\n",
    "            distances.append((d,index))\n",
    "        distances = sorted(distances)\n",
    "\n",
    "        k_nearest_neighbors = distances[0:k]\n",
    "\n",
    "        #Getting the labels of y for each neighbor of the query point\n",
    "        for neighbor in k_nearest_neighbors:\n",
    "            index = neighbor[1]\n",
    "            label = y_train['target'].iloc[index]\n",
    "            labels.append(label)\n",
    "\n",
    "        prediction = statistics.mode(labels)\n",
    "        predictions.append(prediction)\n",
    "        y_predictions = pd.DataFrame(data={'predictions':predictions})\n",
    "\n",
    "    return y_predictions\n",
    "\n",
    "def assign_evaluation_metric_label(target, prediction):\n",
    "\n",
    "    if target == 0 and prediction == 0:\n",
    "        return 'TN'\n",
    "    if target == 0 and prediction == 1:\n",
    "        return 'FP'\n",
    "    if target == 1 and prediction == 0:\n",
    "        return 'FN'\n",
    "    if target == 1 and prediction == 1:\n",
    "        return 'TP'\n",
    "    \n",
    "def get_evaluation_metrics(y_test, y_predictions):\n",
    "    y_test_predictions_concat = pd.concat([y_test, y_predictions], axis=1)\n",
    "    evaluation_metric_labels = list(y_test_predictions_concat.apply(lambda row: assign_evaluation_metric_label(row['target'], row['predictions']), axis=1))\n",
    "    tp = evaluation_metric_labels.count('TP')\n",
    "    fp = evaluation_metric_labels.count('FP')\n",
    "    fn = evaluation_metric_labels.count('FN')\n",
    "    tn = evaluation_metric_labels.count('TN')\n",
    "    recall = tp/(tp+fn) if tp != 0 or fn != 0 else 0\n",
    "    precision = tp/(tp+fp) if tp != 0 or fp != 0 else 0\n",
    "    fpr = fp/(fp + tn) if fp != 0 or tn != 0 else 0\n",
    "    f1_score = 2*((precision*recall)/(precision+recall)) if precision + recall != 0 else 0\n",
    "    accuracy = (tp + tn)/y_test_predictions_concat.shape[0]\n",
    "    conf_matrix = np.array([[tp, fp],\n",
    "                       [fn, tn]])\n",
    "    \n",
    "    return  conf_matrix, recall, precision, fpr, f1_score, accuracy\n",
    "\n",
    "def cross_validation(x_train, y_train, k_values, number_of_folds, distance_func):\n",
    "    random_seed = 23\n",
    "    fold_assignments = pd.DataFrame(columns=['assignments'], index=range(x_train.shape[0]))\n",
    "    fold_size = len(x_train) // number_of_folds\n",
    "    begin = 0\n",
    "    end = fold_size\n",
    "    for i in range(1,number_of_folds+1):\n",
    "        fold_assignments.iloc[begin:end, [0]] = i\n",
    "        begin += fold_size\n",
    "        end += fold_size\n",
    "    # fold_assignments = fold_assignments.sample(frac=1, random_state=random_seed, replace=False).reset_index(drop=True)\n",
    "    \n",
    "    k_evaluation_metrics_table = pd.DataFrame(columns=[str(k) for k in k_values], index=range(1, number_of_folds+1))\n",
    "    for i in range(1, number_of_folds+1):\n",
    "        x_validation_fold = x_train[fold_assignments['assignments'] == i]\n",
    "        y_validation_fold = y_train[fold_assignments['assignments'] == i]\n",
    "        x_train_folds = x_train[fold_assignments['assignments'] != i]\n",
    "        y_train_folds = y_train[fold_assignments['assignments'] != i]\n",
    "\n",
    "        x_validation_fold.reset_index(drop=True, inplace=True)\n",
    "        y_validation_fold.reset_index(drop=True, inplace=True)\n",
    "        x_train_folds.reset_index(drop=True, inplace=True)\n",
    "        y_train_folds.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        k_evaluation_metrics = []\n",
    "        for k in k_values:\n",
    "            # print(x_train_folds.head()['mean radius'],y_train_folds.head(10))\n",
    "            y_predictions = knn(x_train_folds, y_train_folds, x_validation_fold, k, distance_func)\n",
    "            # print(y_predictions.head(10))\n",
    "            conf_matrix, recall, precision, fpr, f1_score, accuracy = get_evaluation_metrics(y_validation_fold, y_predictions)\n",
    "            k_evaluation_metrics.append(f1_score)\n",
    "        k_evaluation_metrics_table.loc[i] = k_evaluation_metrics\n",
    "\n",
    "    return k_evaluation_metrics_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label proportions:\n",
      "0    0.657143\n",
      "1    0.342857\n",
      "Name: target, dtype: float64\n",
      "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
      "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
      "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
      "       'worst concave points', 'worst symmetry', 'worst fractal dimension'],\n",
      "      dtype='object')\n",
      "(455, 30) (455, 1) (114, 30) (114, 1)\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "breast_cancer_train = pd.read_csv(\"breast_cancer_train.csv\")\n",
    "breast_cancer_test = pd.read_csv(\"breast_cancer_test.csv\")\n",
    "\n",
    "print(f\"Label proportions:\\n{breast_cancer_train['target'].value_counts(normalize=1)}\")\n",
    "\n",
    "x_train = breast_cancer_train.drop('target', axis=1)\n",
    "y_train = breast_cancer_train[['target']]\n",
    "\n",
    "x_test = breast_cancer_test.drop('target', axis=1)\n",
    "y_test = breast_cancer_test[['target']]\n",
    "\n",
    "print(x_train.columns)\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating k = 31 with Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.9385964912280702\n",
      " Recall: 0.875\n",
      " Precision: 1.0\n",
      " F1-Score: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "y_predictions = knn(x_train, y_train, x_test, 31, euclidean_distance)\n",
    "\n",
    "conf_matrix, recall, precision, fpr, f1_score, accuracy = get_evaluation_metrics(y_test, y_predictions)\n",
    "\n",
    "print(f' Accuracy: {accuracy}\\n Recall: {recall}\\n Precision: {precision}\\n F1-Score: {f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1         3         7        15        31        63       127\n",
      "1  0.966667  0.983051  0.965517  0.965517  0.947368  0.928571  0.867925\n",
      "2  0.965517  0.933333  0.912281  0.912281  0.909091  0.888889  0.846154\n",
      "3  0.915254  0.949153  0.965517  0.947368  0.912281  0.912281  0.867925\n",
      "4  0.898551  0.925373  0.892308     0.875     0.875   0.83871       0.8\n",
      "5   0.95082       1.0       1.0  0.983607  0.983607       1.0  0.888889\n"
     ]
    }
   ],
   "source": [
    "print(cross_validation(x_train, y_train, [1,3,7,15,31,63,127], 5, euclidean_distance))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_virtual_environment_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
